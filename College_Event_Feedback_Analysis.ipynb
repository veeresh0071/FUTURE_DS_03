{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201b89a4",
   "metadata": {},
   "source": [
    "\n",
    "# College Event Feedback Analysis – Notebook\n",
    "\n",
    "**Source file:** `student_feedback.csv`\n",
    "\n",
    "This notebook loads the survey data, cleans it, computes rating summaries, performs a lightweight lexicon-based sentiment analysis on the free-text feedback, and generates plots. It concludes with auto-generated recommendations for organizers.\n",
    "\n",
    "> Note: The sentiment model is a compact rule-based approach (offline-friendly) and is intended for quick diagnostics. For production/academic use, consider VADER/TextBlob with proper lexicons.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "dec3d427",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(r\"/mnt/data/student_feedback.csv\")\n",
    "df.columns = [str(c).strip() for c in df.columns]\n",
    "df.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50adf945",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_text_col(df):\n",
    "    candidates = [c for c in df.columns if any(k in c.lower() for k in [\"feedback\",\"comment\",\"suggestion\",\"remarks\",\"review\",\"what did\",\"improve\"])]\n",
    "    if candidates:\n",
    "        lens = {c: df[c].astype(str).str.len().mean() for c in candidates}\n",
    "        return max(lens, key=lens.get)\n",
    "    obj_cols = [c for c in df.columns if df[c].dtype == 'object']\n",
    "    if obj_cols:\n",
    "        lens = {c: df[c].astype(str).str.len().mean() for c in obj_cols}\n",
    "        return max(lens, key=lens.get)\n",
    "    return None\n",
    "\n",
    "numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "keyword_candidates = [c for c in df.columns if any(k in c.lower() for k in [\"rating\",\"satisfaction\",\"organis\",\"content\",\"speaker\",\"overall\",\"recommend\",\"experience\",\"session\",\"timing\",\"management\",\"audio\",\"visual\",\"venue\",\"food\"])]\n",
    "for c in keyword_candidates:\n",
    "    if c not in numeric_cols:\n",
    "        coerced = pd.to_numeric(df[c], errors='coerce')\n",
    "        if coerced.notna().mean() > 0.6:\n",
    "            df[c] = coerced\n",
    "            numeric_cols.append(c)\n",
    "\n",
    "text_col = detect_text_col(df)\n",
    "numeric_cols, text_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean = df.copy()\n",
    "if text_col:\n",
    "    df_clean[text_col] = df_clean[text_col].astype(str).str.strip()\n",
    "    df_clean[text_col] = df_clean[text_col].replace({'': np.nan, 'nan': np.nan, 'NaN': np.nan})\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "for c in numeric_cols:\n",
    "    col = df_clean[c]\n",
    "    if col.dropna().between(1,5).mean() > 0.7:\n",
    "        df_clean.loc[~col.between(1,5), c] = np.nan\n",
    "    elif col.dropna().between(0,10).mean() > 0.7:\n",
    "        df_clean.loc[~col.between(0,10), c] = np.nan\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "positive_words = set(\"\"\"\n",
    "amazing awesome great good excellent fantastic helpful friendly engaging informative\n",
    "enjoyed love loved enjoyable outstanding superb wonderful inspiring impressive\n",
    "smooth organized well-organized punctual fun entertaining valuable insightful\n",
    "\"\"\".split())\n",
    "\n",
    "negative_words = set(\"\"\"\n",
    "bad poor boring disappointed disappointing delay delayed late noisy loud\n",
    "confusing unclear unorganized unorganised disorganized disorganised messy\n",
    "crowded mismanaged terrible awful worst horrible long wait waiting queue queues\n",
    "overpriced costly expensive dull irrelevant content short time limited\n",
    "rude unhelpful\n",
    "\"\"\".split())\n",
    "\n",
    "def simple_sentiment(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return np.nan\n",
    "    tokens = [t.strip(\".,!?;:()[]{}'\\\"\").lower() for t in text.split()]\n",
    "    pos = sum(1 for t in tokens if t in positive_words)\n",
    "    neg = sum(1 for t in tokens if t in negative_words)\n",
    "    score = pos - neg\n",
    "    if score > 0:\n",
    "        return \"positive\"\n",
    "    elif score < 0:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "if text_col:\n",
    "    df_clean['Sentiment'] = df_clean[text_col].apply(simple_sentiment)\n",
    "\n",
    "sentiment_counts = df_clean['Sentiment'].value_counts(dropna=True) if 'Sentiment' in df_clean else None\n",
    "sentiment_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rating_summary = None\n",
    "if numeric_cols:\n",
    "    rating_summary = pd.DataFrame({\n",
    "        'Metric': numeric_cols,\n",
    "        'Count': [df_clean[c].notna().sum() for c in numeric_cols],\n",
    "        'Mean': [df_clean[c].mean() for c in numeric_cols],\n",
    "        'Median': [df_clean[c].median() for c in numeric_cols],\n",
    "        'StdDev': [df_clean[c].std() for c in numeric_cols],\n",
    "    }).sort_values('Mean', ascending=False)\n",
    "rating_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if rating_summary is not None and not rating_summary.empty:\n",
    "    plt.figure()\n",
    "    plt.bar(rating_summary['Metric'].astype(str), rating_summary['Mean'])\n",
    "    plt.title('Average Ratings by Metric')\n",
    "    plt.xlabel('Metric')\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    for c in rating_summary['Metric'].astype(str).tolist()[:6]:\n",
    "        if pd.api.types.is_numeric_dtype(df_clean[c]):\n",
    "            plt.figure()\n",
    "            plt.hist(df_clean[c].dropna())\n",
    "            plt.title(f'Distribution of Ratings: {c}')\n",
    "            plt.xlabel('Score')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "if 'Sentiment' in df_clean:\n",
    "    counts = df_clean['Sentiment'].value_counts().reindex(['positive','neutral','negative']).fillna(0).astype(int)\n",
    "    if counts.sum() > 0:\n",
    "        plt.figure()\n",
    "        plt.pie(counts.values, labels=counts.index, autopct='%1.1f%%')\n",
    "        plt.title('Sentiment Distribution (Feedback Text)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recommendations = []\n",
    "if rating_summary is not None and not rating_summary.empty:\n",
    "    low_metrics = rating_summary[rating_summary['Mean'] < (rating_summary['Mean'].max() - 0.75)]\n",
    "    for _, row in low_metrics.iterrows():\n",
    "        metric = row['Metric']\n",
    "        mean = row['Mean']\n",
    "        recommendations.append(f\"Improve '{metric}': current average {mean:.2f}. Target quick wins before the next event.\")\n",
    "\n",
    "    overall_like = [m for m in rating_summary['Metric'] if 'overall' in str(m).lower() or 'satisfaction' in str(m).lower()]\n",
    "    for m in overall_like:\n",
    "        mean = df_clean[m].mean()\n",
    "        if mean and mean < 4:\n",
    "            recommendations.append(f\"Overall satisfaction for '{m}' is {mean:.2f}. Run a structured post-mortem and prioritize top 3 fixes.\")\n",
    "\n",
    "if 'Sentiment' in df_clean:\n",
    "    from collections import Counter\n",
    "    def extract_keywords(series, focus_set):\n",
    "        tokens = []\n",
    "        for t in series.fillna('').astype(str):\n",
    "            toks = [tok.strip(\".,!?;:()[]{}'\\\"\").lower() for tok in t.split()]\n",
    "            tokens.extend([tok for tok in toks if tok in focus_set])\n",
    "        return Counter(tokens).most_common(5)\n",
    "\n",
    "    concern_words = set(['timing','late','delay','queue','sound','audio','mic','noise','crowd','food','registration','seating','speaker','content','organization','management','venue','wifi','projector','lighting'])\n",
    "    highlight_words = set(['speaker','workshop','networking','games','music','prizes','sessions','organization','volunteers','food'])\n",
    "\n",
    "    neg_texts = df_clean.loc[df_clean['Sentiment']=='negative', text_col] if text_col else pd.Series(dtype=str)\n",
    "    pos_texts = df_clean.loc[df_clean['Sentiment']=='positive', text_col] if text_col else pd.Series(dtype=str)\n",
    "\n",
    "    neg_keys = extract_keywords(neg_texts, concern_words)\n",
    "    pos_keys = extract_keywords(pos_texts, highlight_words)\n",
    "\n",
    "    if neg_keys:\n",
    "        joined = '; '.join([f\"{w} (x{c})\" for w,c in neg_keys])\n",
    "        recommendations.append(f\"Address frequent concerns: {joined}. Assign owners and deadlines.\")\n",
    "\n",
    "    if pos_keys:\n",
    "        joined = '; '.join([f\"{w} (x{c})\" for w,c in pos_keys])\n",
    "        recommendations.append(f\"Double down on what worked: {joined}. Preserve these strengths.\")\n",
    "\n",
    "if not recommendations:\n",
    "    recommendations.append(\"Maintain strengths and run a pre-event pulse survey to identify top 2–3 improvements.\")\n",
    "\n",
    "recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb221457",
   "metadata": {},
   "source": [
    "\n",
    "### Proxy Sentiment from Ratings\n",
    "No free-text feedback was available, so we derived a **proxy sentiment** from the average of all rating metrics per response:\n",
    "- **Positive**: average ≥ 4.0 (on a 1–5 scale) or ≥ 8.0 (on a 0–10 scale)\n",
    "- **Neutral**: average ≥ 3.0 (1–5) or ≥ 5.0 (0–10) and below positive threshold\n",
    "- **Negative**: below neutral threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ef8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row_avg = df_clean[numeric_cols].mean(axis=1)\n",
    "scale_1_5 = sum(df_clean[c].dropna().between(1,5).mean() for c in numeric_cols) / max(len(numeric_cols),1) > 0.5\n",
    "\n",
    "if scale_1_5:\n",
    "    pos_thresh, neu_thresh = 4.0, 3.0\n",
    "else:\n",
    "    pos_thresh, neu_thresh = 8.0, 5.0\n",
    "\n",
    "proxy_sentiment = np.where(row_avg >= pos_thresh, \"positive\",\n",
    "                   np.where(row_avg >= neu_thresh, \"neutral\", \"negative\"))\n",
    "df_clean[\"ProxySentimentFromRatings\"] = proxy_sentiment\n",
    "df_clean[\"ProxySentimentFromRatings\"].value_counts()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
